| Scenario Category                           | Scenario / Use Case              | Expected Behavior / Response                         | Kafka Connector Configuration / Notes                                                                                                                 |
| ------------------------------------------- | -------------------------------- | ---------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Basic Data Ingestion**                    | Insert new document in Couchbase | Record appears in Kafka topic with correct key/value | `connector.class=CouchbaseSourceConnector`, `couchbase.topic`, `couchbase.bucket`, `couchbase.collections`, `RawJsonSourceHandler` or `JsonConverter` |
|                                             | Update document                  | Updated fields reflect in Kafka message              | `couchbase.stream.from=SAVED_OFFSET_OR_BEGINNING`, SMTs handle transformations                                                                        |
|                                             | Delete document                  | Tombstone message emitted (if enabled)               | `couchbase.delete.enabled=true`                                                                                                                       |
| **Conditional Filtering / Transformations** | Filter documents by criteria     | Only matching documents are published                | SMT: `ConditionalDocumentFilter`, `transforms.filterDocs.couchbase.conditional.filter.expr`                                                           |
|                                             | Drop fields / blacklist          | Unwanted fields removed before sending               | SMT: `ReplaceField$Value`, `blacklist=<fields_to_drop>`                                                                                               |
|                                             | Flatten nested objects           | Arrays / objects accessible for filtering            | SMT logic handles flattening or JEXL expression supports nested access                                                                                |
| **Resilience & Recovery**                   | Couchbase node down              | Connector retries and resumes, no data loss          | `couchbase.bootstrap.timeout`, `errors.tolerance=all`, `couchbase.flow.control.buffer`                                                                |
|                                             | Kafka broker down                | Connector buffers data and retries                   | `couchbase.flow.control.buffer`, Kafka producer retries                                                                                               |
|                                             | Connector restart                | Resume from last committed offset                    | `couchbase.stream.from=SAVED_OFFSET_OR_BEGINNING`                                                                                                     |
|                                             | Network partition                | Connector retries, no data loss                      | `errors.tolerance=all`, proper logging                                                                                                                |
| **Array / Nested Object Handling**          | Outer-level field existence      | Record filtered if missing                           | JEXL: `field != null` or `field == null` for `$exists` equivalent                                                                                     |
|                                             | Array length check               | Only process non-empty arrays                        | JEXL: `array != null && array.size() > 0`                                                                                                             |
|                                             | Inner object fields              | Optional: check nested fields in arrays              | JEXL: `array[0].field != null`                                                                                                                        |
| **Error Handling**                          | Invalid JSON / unsupported type  | Record skipped or logged                             | `errors.tolerance=all`, `errors.log.enable=true`, `errors.log.include.messages=true`                                                                  |
|                                             | Transformation errors            | Connector continues processing other records         | SMT wraps logic in try/catch, proper logging                                                                                                          |
|                                             | Retry / Backpressure             | Data buffered during high load, no loss              | `couchbase.flow.control.buffer`, `couchbase.compression=ENABLED`                                                                                      |
| **Security & Authentication**               | TLS / secure connection          | Secure comms between Kafka and Couchbase             | `couchbase.enable.tls=true`, `couchbase.trust.certificate.path`                                                                                       |
|                                             | Credentials / auth               | Connector can authenticate successfully              | `couchbase.username`, `couchbase.password`                                                                                                            |
| **Offset / Checkpoint**                     | Connector crash or restart       | Resume from last offset without reprocessing         | `couchbase.stream.from=SAVED_OFFSET_OR_BEGINNING`                                                                                                     |
| **Performance**                             | High throughput / bulk insert    | Connector handles load, no data loss                 | `couchbase.flow.control.buffer`, monitoring lag and resource usage                                                                                    |


| Scenario Category      | Scenario / Use Case                  | Expected Behavior / Response                                                                      | Kafka Connector Configuration / Notes                                                                      |
| ---------------------- | ------------------------------------ | ------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **Polling & Delivery** | Regular polling of Couchbase changes | Connector polls Couchbase bucket/collections and publishes new changes to Kafka in near real-time | `couchbase.persistence.polling.interval` (e.g., `100ms`), `tasks.max` controls parallelism                 |
|                        | Polling lag / message delay          | Messages are published with minimal lag; lag can be monitored via Kafka metrics                   | Monitor `consumer_lag` in Kafka; tune `couchbase.flow.control.buffer` if high load                         |
|                        | Connector task crash during poll     | Connector resumes from last committed offset without data loss                                    | `couchbase.stream.from=SAVED_OFFSET_OR_BEGINNING`, ensure proper `offset.storage` (Kafka internal)         |
|                        | Kafka broker unavailable during poll | Connector buffers polled messages, retries sending until broker is available                      | `couchbase.flow.control.buffer` defines max buffer, `couchbase.compression=ENABLED` can improve throughput |
|                        | Multiple connector tasks             | Each task polls partitions and updates offsets independently; ensure messages are not duplicated  | `tasks.max > 1`, `couchbase.collections` must be partitioned correctly                                     |
|                        | High frequency inserts               | Connector handles bursts of inserts without dropping messages                                     | Tune `couchbase.flow.control.buffer`, `polling.interval`, and monitor task metrics                         |
|                        | Offset persistence                   | After successful poll and send, offsets are committed                                             | Kafka Connect handles offsets internally; verify via `__consumer_offsets` topic or connector status        |
